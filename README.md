# Simply eBay - AI-Powered Mobile Selling Assistant
## Alpha Version 0.01 - Under Development ðŸš§

![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=next.js&logoColor=white)
![Gun.js](https://img.shields.io/badge/Gun.js-P2P_Database-FF6B6B?style=for-the-badge&logo=javascript)
![TensorFlow.js](https://img.shields.io/badge/TensorFlow.js-AI_Engine-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![LlamaFile](https://img.shields.io/badge/LlamaFile-Local_AI-4B0082?style=for-the-badge)
![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=node.js&logoColor=white)

**Simply eBay: A mobile-first app that helps you create eBay listings using AI. Point your camera at items, get AI-powered descriptions and pricing suggestions, then list to eBay with ease.**

## ðŸŒŸ **What We're Building**

- ðŸ“± **Mobile-First Camera Interface**: Point your camera at items for AI-powered identification and pricing
- ðŸ”’ **Privacy-First Local AI**: SmolVLM + LlamaFile runs on your device, keeping your data private
- ðŸ”— **Offline-Capable**: Gun.js P2P database for offline-first data sync
- ðŸ›’ **eBay Integration**: Generate and create eBay listings from your scanned items

### ðŸŽ¯ **The Vision: Simple Tools That Work**

We're building a focused tool that solves one specific problem: making it easier to create eBay listings from your phone. No feature creep, no swiss-army knife - just a simple, effective tool that does one thing well.

**The Goal:** Point. Scan. List. Done.  
**The Approach:** Mobile-first, privacy-first, offline-capable.

<p align="center">
  <img src="ebaygarage.png" alt="Simply eBay App Interface" width="80%" style="max-width: 600px;">
</p>

### ï¿½ï¸ **Development Journey**

**Collaborative Development:** Built through human-AI collaboration with Claude providing technical innovation, GitHub Copilot for code assistance, and focused product development.

**Learning Experience:** Through iterations and debugging, we learned the importance of focusing on core functionality rather than building too many features at once.

**Privacy Focus:** Built with local AI processing to keep your data on your device unless you choose to list on eBay.

### ðŸ”§ **Built With Open Source**

- **ðŸ”« [Gun.js](https://gun.eco/)** - P2P database for offline-first data sync
- **ðŸ§  [TensorFlow.js](https://www.tensorflow.org/js)** - Machine learning in JavaScript
- **ðŸ¦™ [LlamaFile](https://github.com/Mozilla-Ocho/llamafile)** - Local AI model execution
- **âš›ï¸ [Next.js](https://nextjs.org/)** - React framework for web applications
- **ðŸ‘ï¸ SmolVLM** - Vision language model for image recognition
- **ðŸª [eBay API](https://developer.ebay.com/)** - Marketplace integration

![Open Source](https://img.shields.io/badge/Built_with-Open_Source-red?style=for-the-badge)
![Made with Love](https://img.shields.io/badge/Made_with-â¤ï¸-red?style=for-the-badge)

> **ï¿½ Point. Scan. List. Done.**  
> *A mobile-first app for creating eBay listings with AI assistance and offline capabilities.*

---

## âœ¨ **Current Features**

ðŸ“± **Mobile Camera Interface** â€¢ Point your camera at items for AI identification and pricing suggestions  
ï¿½ **P2P Data Sync** â€¢ Gun.js powered offline-first data storage and sync  
ðŸ§  **Local AI Processing** â€¢ SmolVLM + LlamaFile for privacy-focused on-device computer vision  
ðŸ›’ **eBay Integration** â€¢ Generate listings and connect to eBay marketplace  
ðŸŽ¨ **Touch-Friendly UI** â€¢ Mobile-optimized interface with intuitive interactions  
ðŸ”’ **Privacy-First** â€¢ All AI processing happens locally on your device  

---

## ðŸŽ¬ **See It In Action**

```bash
# ðŸš€ One-command startup (handles everything!)
./startup.sh
```

**Then visit:** `http://localhost:3000` ðŸ“±

---

## âš™ï¸ **Technical Architecture**

### ðŸ”§ **Tech Stack**

- **ðŸ“± Frontend**: Next.js with mobile-first responsive design
- **ðŸŽ¥ Computer Vision**: SmolVLM-Instruct for item recognition
- **ðŸ§  AI Processing**: LlamaFile for local inference
- **ðŸ”— Database**: Gun.js for P2P, offline-first data sync
- **ðŸ›’ Marketplace**: eBay API for listing creation
- **ðŸ” Search**: TensorFlow.js for semantic item matching

### ðŸŒ **System Design**

```text
ðŸ“± Next.js App â†â†’ ðŸ”— Gun.js P2P Network â†â†’ ðŸ§  LlamaFile (Local AI)
                           â†“
                   ðŸ›’ eBay API Integration
```

---

## ï¿½ **Current Status**

This is an **alpha version** under active development. Core features are being built and tested:

âœ… **Completed:**
- Mobile-responsive Next.js frontend
- Gun.js P2P database integration with authentication
- LlamaFile local AI server setup
- Basic camera interface components
- eBay API integration framework

ðŸ”„ **In Progress:**
- AI-powered item recognition
- Automated pricing suggestions
- Complete eBay listing workflow
- Mobile PWA optimization

â³ **Planned:**
- Enhanced UI/UX polish
- Advanced camera features
- Batch listing capabilities
- Performance optimizations

## ðŸ“‹ **Getting Started**

This app requires downloading a large AI model file. Please follow the setup instructions below.

â€¼ï¸ **Prerequisite: Download LlamaFile AI Model**

Simply eBay uses LlamaFile to run the AI model locally on your machine for privacy and offline capabilities. Due to its size (around 4-5GB), the model file (`llava-v1.5-7b-q4.llamafile`) is NOT included in this repository. You need to download it manually:

1. **Visit the LlamaFile GitHub repository:** [Mozilla-Ocho/llamafile](https://github.com/Mozilla-Ocho/llamafile)
2. **Navigate to the releases section** or look for model download links. The specific model used by this project is `llava-v1.5-7b-q4.llamafile`. You can often find it linked from their main README or other community resources if not directly in releases.
    - A direct link for a compatible Llamafile (like the one used in development, `llava-v1.5-7b-Q4_K_M.llamafile`) can usually be found via Hugging Face or other model repositories that package for Llamafile. For example, search for "llava-v1.5-7b llamafile".
3. **Download the `llava-v1.5-7b-q4.llamafile` file.**
4. **Place the downloaded file** into the root directory of this project (i.e., `/Users/alanhelmick/Documents/GitHub/ebay-helper/llava-v1.5-7b-q4.llamafile`).
5. **Make it executable:**

    ```bash
    chmod +x llava-v1.5-7b-q4.llamafile
    ```

The `startup.sh` and `start-llava.sh` scripts expect this file to be present and executable in the project root.

## âš¡ **One-Command Launch**

```bash
# Make sure you're in the project directory
cd ebay-helper

# Launch everything at once (handles all services automatically!)
./startup.sh
```

**ðŸŽ¯ After startup, visit:** `http://localhost:3000`

The splash screen will appear for 3 seconds, then redirect to the beautiful neumorphic onboarding flow!

## ðŸ› ï¸ **What Gets Started**

- **ðŸ”« Gun.js P2P Relay** â†’ `http://localhost:8765`
- **ðŸ¤– LlamaFile AI Server** â†’ `http://localhost:8080`
- **ðŸ“± Simply eBay App** â†’ `http://localhost:3000`

## ðŸ“± **Mobile Testing**

- **ðŸ“± WiFi Access**: `http://YOUR_IP:3000` (IP shown in terminal)
- **ðŸ” QR Code**: Scan with your phone for instant access
- **âš¡ PWA Ready**: Add to home screen for native app feel

## ðŸ”§ **Manual Service Control**

```bash
# If you prefer manual control:

# 1. Start Gun.js P2P relay
npm run gun-relay &

# 2. Start AI server
./start-llava.sh &

# 3. Start Next.js app
npm run dev
```

## ðŸ†˜ **Troubleshooting**

### ðŸš¨ **Port Already in Use**

```bash
# Kill processes on ports
lsof -ti:3000 | xargs kill -9    # Next.js
lsof -ti:8080 | xargs kill -9    # LlamaFile
lsof -ti:8765 | xargs kill -9    # Gun.js
```

### âš ï¸ **Startup Issues**

- **Problem**: "Permission denied"
  - **Fix**: `chmod +x startup.sh start-llava.sh cleanup.sh llava-v1.5-7b-q4.llamafile` (ensure all scripts and the model file are executable)
- **Problem**: "Command not found"
  - **Fix**: `npm install` first
- **Problem**: "Model not found" or LlamaFile server doesn't start.
  - **Fix**: Ensure you have downloaded `llava-v1.5-7b-q4.llamafile`, placed it in the project root, and made it executable as per the "Prerequisite: Download LlamaFile AI Model" section above. The file must be named exactly `llava-v1.5-7b-q4.llamafile` in the root of the project.
- **Problem**: LlamaFile error "no such file or directory" when running `./llava-v1.5-7b-q4.llamafile`.
  - **Fix (macOS with Apple Silicon)**: You might need to install `qemu-system-x86_64` if it's an x86_64 llamafile. `brew install qemu`. Llamafiles are generally self-contained but cross-architecture execution might need QEMU. However, try to find an ARM64-compatible Llamafile if possible for better performance.

### ðŸŒ **Network Issues**

- **Local Only**: All services run locally (no internet required after setup)
- **Firewall**: Allow ports 3000, 8080, 8765 if using across devices
- **Performance**: M1/M2 Macs run AI models much faster than Intel

### ðŸ”„ **Clean Restart**

```bash
# Full reset and restart
./cleanup.sh && ./startup.sh
```

---

## ðŸ™ **Development Team**

> *"Focus beats feature creep every time. Build one thing that works well."*

### ðŸ‘¥ **Contributors**

**ðŸ¤– Claude (Anthropic)** - *AI Development Partner*  
![Claude](https://img.shields.io/badge/Claude-AI_Assistant-8A2BE2?style=flat-square)  
Technical architecture, code generation, and debugging assistance throughout the development process.

**ðŸ§  GitHub Copilot** - *Code Completion & Assistance*  
![Copilot](https://img.shields.io/badge/GitHub-Copilot-000000?style=flat-square&logo=github)  
Code suggestions, completion, and development support.

**ðŸŽ¯ Alan Helmick** - *Product Development & Vision*  
![Mira AI](https://img.shields.io/badge/Mira_AI-Founder-222222?style=flat-square)  
Product direction, user experience design, and project coordination.

**âš¡ Maximus** - *Technical Contributor*  
![Contributor](https://img.shields.io/badge/Contributor-Technical-FF6C37?style=flat-square)  
System optimization and technical insights.


